# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11rshqWfBQA51MY_mX9iYThFjLuEOWp3g
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
# we import the pandas library and give it a nickname pd
# %matplotlib inline
#Built-in magic command used for making your plot outputs appear and be stored within the notebook.
import matplotlib.pyplot as plt
#Matplotlib is a popular Python library for creating and customizing plots and visualizations.
#Matplotlib.pyplot is a submodule of matplotlib that provides a MATLAB-like interface for plotting
nyc=pd.read_csv('/content/ave_hi_nyc_jan_1895-2018.csv')
#used to upload the dataset
nyc.head()
# Assuming 'nyc' is a DataFrame
# Display the first 5 rows of the DataFrame

nyc.tail()
# Assuming 'nyc' is a DataFrame
# Display the last 5 rows of the DataFrame

nyc.sample(20)
# Assuming 'nyc' is a DataFrame
# Sample 20 random rows from the DataFrame

nyc.columns =['Date','Temperature','Anomaly']
# Assuming 'nyc' is a DataFrame
# Used to assign new column names to a DataFrame named nyc.

nyc.head()
# Assuming 'nyc' is a DataFrame
# Display the first 5 rows of the renamed columns DataFrame

nyc.Date=nyc.Date.floordiv(100)
# Assuming 'nyc' is a DataFrame
# Perform floor division by 100 on the 'Date' column

nyc.head()
# Assuming 'nyc' is a DataFrame
# Display the first 5 rows after performing floor division by 100 on the 'Date' column

nyc.shape
# Assuming 'nyc' is a DataFrame
# Get the shape of the DataFrame,representing the number of rows and columns in the DataFrame.

nyc.tail()
# Assuming 'nyc' is a DataFrame
#Display the last 5 rows of the Dataset to show the shape was correct

from sklearn.model_selection import train_test_split
#Used to split the data into training (80%) and testing (20%) sets.
#A submodule within scikit-learn that contains functions related to model selection, including train-test splitting.

nyc.Date.values.shape
# Assuming 'nyc' is a DataFrame
# Access the 'Date' column, convert to NumPy array, and get the shape

X_train,X_test,y_train,y_test=train_test_split(nyc.Date.values.reshape(-1,1), nyc.Temperature.values,random_state=11)
# The training set for features (2D array).
#The testing set for features (2D array).
#The training set for labels ('Temperature').
#The testing set for labels ('Temperature').
#This function takes the features and labels (in this case, 'Date' and 'Temperature') and splits them into training and testing sets.

X_train.shape
#will give you a tuple with two elements:
#The first element represents the number of samples (rows) in the training set.
#The second element represents the number of features (columns) in the training set.

X_test.shape
#This is the testing set for the input features (in this case, 'Date').
#This is an attribute in NumPy arrays that returns a tuple representing the dimensions of the array.

93+31
#A simple arithmetic expression

93/124*100
#A simple arithmetic expression

#Training the model
from sklearn.linear_model import LinearRegression
#Used to create a linear regression model, fit it to the provided data

linear_regression=LinearRegression()
#creating an instance of the LinearRegression class in scikit-learn and assigning it to the variable linear_regression.

linear_regression

linear_regression.fit(X=X_train, y=y_train)
#using the fit method of a linear regression model (presumably an instance of the LinearRegression class from scikit-learn) to train the model on a training dataset.

#Equation M and C
linear_regression.coef_
# A fitted linear regression model (such as one created using scikit-learn's LinearRegression class) represents the coefficients of the linear regression equation.
# Access the coefficient

linear_regression.intercept_
#A fitted linear regression model (such as one created using scikit-learn's LinearRegression class) represents the y-intercept of the linear regression equation.
# Access the intercept

equation: $ Temperature = 0.01939167 * Date - 0.30779820252656265$

(0.01939167 * 2014) - 0.30779820252656265
#A simple arithmetic expression.

# Testing the Model
predicted = linear_regression.predict(X_test)

expected = y_test

for p,e in zip(predicted[::], expected[::]):
  print(f'Predicted: {p:.2f}, Expected: {e:.2f}')

for p,e in zip(predicted[::], expected[::]):
  print(f'Predicted: {p:.2f}, Expected: {e:.2f}, Error: {e-p:.2f}')

# Mean Absolute Error (MAE)
#
from sklearn.metrics import mean_absolute_error

print("MAE", mean_absolute_error(expected,predicted))

#RMSE - Root Mean Squared Error
from sklearn.metrics import mean_squared_error

import numpy as np
print(f'RMSE',np.log(np.sqrt(mean_squared_error(expected, predicted)) ))

# R Squared (R2)
from sklearn.metrics import r2_score
r2=r2_score(expected,predicted)
r2

# predict future model
predict=(lambda x: linear_regression.coef_ *x + linear_regression.intercept_)
predict(2014)

predict(2022)

predict(1800)

# Visualizing the dataset with a Regression Line
import seaborn as sns
axes=sns.scatterplot(data=nyc, x='Date',y='Temperature',
                     hue='Temperature', palette='winter', legend=False)
axes.set_ylim(10,70)
x=np.array([min(nyc.Date.values),max(nyc.Date.values)])
y=predict(x)
line=plt.plot(x,y)

x

y